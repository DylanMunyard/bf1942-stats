apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: clickhouse-data
  namespace: clickhouse
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: managed-premium
  resources:
    requests:
      storage: 128Gi

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: clickhouse-config
  namespace: clickhouse
data:
  users.xml: |
    <clickhouse>
      <users>
        <default>
          <password></password>
          <networks>
            <ip>::/0</ip>
          </networks>
          <profile>default</profile>
          <quota>default</quota>
          <access_management>1</access_management>
        </default>
      </users>
      <profiles>
        <default>
          <http_max_uri_size>209715200</http_max_uri_size>
          <max_query_size>209715200</max_query_size>
          
          <max_memory_usage>10000000000</max_memory_usage>
          <max_memory_usage_for_user>12000000000</max_memory_usage_for_user>
          <max_bytes_before_external_group_by>4000000000</max_bytes_before_external_group_by>
          <max_bytes_before_external_sort>4000000000</max_bytes_before_external_sort>
          <max_insert_block_size>1048576</max_insert_block_size>
        </default>
      </profiles>
      
      <max_server_memory_usage_to_ram_ratio>0.8</max_server_memory_usage_to_ram_ratio>
      <merge_tree>
        <max_suspicious_broken_parts>5</max_suspicious_broken_parts>
      </merge_tree>
    </clickhouse>
  config.xml: |
    <clickhouse>
      <logger>
        <console>1</console>
      </logger>
      <text_log>
        <level>information</level>
        <ttl><![CDATA[DELETE WHERE event_date < today() - INTERVAL 7 DAY]]></ttl>
      </text_log>
      <prometheus>
        <endpoint>/metrics</endpoint>
        <port>9363</port>
        <metrics>true</metrics>
        <events>true</events>
        <asynchronous_metrics>true</asynchronous_metrics>
      </prometheus>
      <storage_configuration>
        <disks>
          <backups>
            <type>local</type>
            <path>/backups/</path>
          </backups>
        </disks>
      </storage_configuration>
      <backups>
        <allowed_disk>backups</allowed_disk>
        <allowed_path>/backups/</allowed_path>
      </backups>
    </clickhouse>
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: clickhouse
  namespace: clickhouse
  annotations:
    argocd.argoproj.io/sync-wave: "1"
spec:
  replicas: 1
  selector:
    matchLabels:
      app: clickhouse
  template:
    metadata:
      labels:
        app: clickhouse
    spec:
      priorityClassName: 1942-services
      nodeSelector:
        workload: core
      containers:
        - name: clickhouse
          image: clickhouse/clickhouse-server:24.12-alpine
          ports:
            - containerPort: 8123
              name: http
            - containerPort: 9000
              name: native
            - containerPort: 9363
              name: metrics
          lifecycle:
            postStart:
              exec:
                command:
                  - /bin/sh
                  - -c
                  - |
                    # Wait for ClickHouse to be ready
                    until clickhouse-client --query "SELECT 1" > /dev/null 2>&1; do
                      echo "Waiting for ClickHouse to start..."
                      sleep 2
                    done

                    # Check if backup exists and database is empty
                    if [ -f "/backups/bfstats-native.zip" ] && [ -z "$(clickhouse-client --query 'SHOW TABLES' 2>/dev/null)" ]; then
                      echo "Restoring ClickHouse database from backup..."
                      clickhouse-client --query "RESTORE DATABASE default FROM Disk('backups', 'bfstats-native.zip')" || echo "Restore failed or already completed"
                      echo "Restore process completed"
                    fi
          volumeMounts:
            - name: stats-data
              mountPath: /var/lib/clickhouse
            - name: backups
              mountPath: /backups
            - name: config
              mountPath: /etc/clickhouse-server/users.d/users.xml
              subPath: users.xml
            - name: config
              mountPath: /etc/clickhouse-server/config.d/config.xml
              subPath: config.xml
          securityContext:
            capabilities:
              add:
                - IPC_LOCK
                - SYS_NICE
          resources:
            limits:
              memory: "12Gi"
            requests:
              memory: "2Gi"
          livenessProbe:
            httpGet:
              path: /ping
              port: 8123
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 1
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /ping
              port: 8123
            initialDelaySeconds: 10
            periodSeconds: 5
            timeoutSeconds: 1

        - name: azure-uploader
          image: mcr.microsoft.com/azure-cli:latest
          command: ["/bin/sh"]
          args:
            - -c
            - |
              while true; do
                # Check if there are any .zip files in /backups (exclude already uploaded and tmp files)
                if [ "$(ls /backups/*.zip 2>/dev/null | grep -v '\.uploaded$' | grep -v '\.tmp$' | wc -l)" -gt 0 ]; then
                  for file in /backups/*.zip; do
                    # Skip files already marked as uploaded and tmp files
                    if [[ "$file" == *.uploaded ]] || [[ "$file" == *.tmp ]]; then
                      continue
                    fi
                    echo "Uploading $file to Azure..."
                    az storage blob upload \
                      --container-name clickhouse \
                      --name "$(basename $file)" \
                      --file "$file" \
                      --overwrite \
                      --connection-string "$AZURE_STORAGE_CONNECTION_STRING"
                    if [ $? -eq 0 ]; then
                      echo "Upload successful, deleting: $(basename $file)"
                      rm -f "$file"
                    else
                      echo "Upload failed for $(basename $file), will retry"
                    fi
                  done
                fi
                sleep 60
              done
          env:
            - name: AZURE_CONFIG_DIR
              value: "/tmp/.azure"
            - name: AZURE_STORAGE_CONNECTION_STRING
              valueFrom:
                secretKeyRef:
                  name: storage-secret
                  key: connection-string
          volumeMounts:
            - name: backups
              mountPath: /backups
          resources:
            requests:
              memory: "64Mi"
              cpu: "50m"
            limits:
              memory: "512Mi"
              cpu: "500m"
      volumes:
        - name: stats-data
          persistentVolumeClaim:
            claimName: clickhouse-data
        - name: backups
          emptyDir: {}
        - name: config
          configMap:
            name: clickhouse-config

---
apiVersion: v1
kind: Service
metadata:
  name: clickhouse-service
  namespace: clickhouse
  labels:
    app: clickhouse
  annotations:
    tailscale.com/expose: "true"
    tailscale.com/hostname: clickhouse-aks
spec:
  type: ClusterIP
  selector:
    app: clickhouse
  ports:
    - name: http
      port: 8123
      targetPort: 8123
      protocol: TCP
    - name: native
      port: 9000
      targetPort: 9000
      protocol: TCP
    - name: metrics
      port: 9363
      targetPort: 9363
      protocol: TCP
---
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: clickhouse-metrics
  namespace: clickhouse
  labels:
    release: kube-prometheus-stack
spec:
  selector:
    matchLabels:
      app: clickhouse
  endpoints:
    - port: metrics
      path: /metrics
      interval: 30s

